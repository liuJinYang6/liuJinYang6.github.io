{"posts":[{"title":"python读写excel文件","content":"用xlrd和xlwt读写excel 首先下载安装xlrd和xlwt这两个库 使用xlrd读取excel # 导入包 import xlrd # 1、打开excel readbook = xlrd.open_workbook(r'\\test\\canying.xlsx') # 2、获取读入的文件的sheet sheet = readbook.sheet_by_index(1)#索引的方式，从0开始 sheet = readbook.sheet_by_name('sheet2')#通过名字定位sheet页 allsheetnames = readbook.sheet_names()#返回所有sheet页名字组成的列表 # 3、获取sheet的最大行数和列数 nrows = sheet.nrows#行 ncols = sheet.ncols#列 # 4、获取某个单元格的值 lng = sheet.cell(x,y) lng = sheet.cell(0,0).value#获取1行1列的表格值，从0开始计数 lat = sheet.cell(1,4).value#获取2行5列的表格值，从0开始计数 # 5、获取某行/某列的值 row_value = sheet.row_values(x) #获取x行的值，从0开始计数 col_value = sheet.col_values(y) #获取y列的值，从0开始计数 使用xlutils.copy写excel # 导入前，先导入xlrd，需要依赖这个包 from xlutils.copy import copy # 1-读取源excel中的所有数据（复制对象） rb = xlrd.open_workbook(excel_dir + '\\\\' + 'data.xls') # 2-复制读取的源excel对象 wb = copy(rb) # 3-通过get_sheet()获取复制对象的sheet页 ws = wb.get_sheet(2) # 4-对sheet页进行写入(传入x和y坐标，和具体写入的value) ws.write(id,2,real) ws.write(id,3,status) # 5-保存excel（具体的excel路径+名称） wb.save(self.excel_dir + '\\\\' + 'data.xls') 注意：运行代码时要关闭excel，否则会报错 使用openpyxl库读写excel ​ xlrd和xlwt处理的是xls文件，单个sheet最大行数是65535，如果数据量超过65535就会遇到：ValueError: row index was 65536, not allowed by .xls format。 ​ 如果有更大需要的，建议使用openpyxl函数，最大行数达到1048576。 # 导入包 import openpyxl # 打开excel file_path = r'D:\\work\\testdata.xlsx' inwb = openpyxl.load_workbook(file_path) # 读取文件 # 获取打开的excel的sheet内容 sheetnames = inwb.get_sheet_names() # 获取所有sheet页的name ws = inwb.get_sheet_by_name(sheetnames[0]) # 按照name获取第一个sheet页的内容 # 获取sheet的最大行数和列数 rows = ws.max_row cols = ws.max_column # 获取某个单元格的值 ws.cell(1, 1).value # 打开将写的表并添加sheet outwb = openpyxl.Workbook() # 打开一个将写的文件 outws = outwb.create_sheet(index=0) # 在将写的文件创建一个新的sheet # 保存 saveExcel = r'D:\\work\\new.xlsx' outwb.save(saveExcel) # 一定要记得保存 注意：最后一定要记得保存，否则就前功尽弃喽😲 ","link":"https://liujinyang6.github.io/post/python-du-xie-excel-wen-jian/"},{"title":"Python读取config-ini文件","content":"读取步骤： 1.导入configparser import configparser 2.实例化一个configparser对象，读取目标配置文件内容 # 1.实例化configparser对象 conf = configparser.ConfigParser() # 2.获取目标.ini文件路径 file_path = os.path.dirname(‘xxxini文件路径’)+&quot;\\\\config.ini&quot; # 3.读取目标文件内的内容(section)，当有中文的时候使用encoding conf.read(file_path,encoding=&quot;utf-8-sig&quot;) config.ini文件格式 获取文件内的所有section sections = conf.sections() print('获取配置文件所有的section', sections) 获取xx section下的所有option options = conf.options('mysql') print('获取指定section下所有option', options) 获取xx section下的所有键值对 items = conf.items('mysql') print('获取指定section下所有的键值对', items) 获取xx section下的某个option value = conf.get('mysql', 'host') print('获取指定的section下的option', value) ","link":"https://liujinyang6.github.io/post/python-du-qu-config-ini-wen-jian/"},{"title":"软件测试流程","content":"Posted on 2018-12-12 | In Hexo 需求分析： - 整体流程图： 需求提取 -&gt; 需求分析 -&gt; 需求评审 -&gt; 更新后的测试需求跟踪xmind - 分析流程： 需求提取： 分析依据（包括：需求矩阵、产品交互图、需求说明书） 获取需求的纬度 客户价值 可以为客户带来哪些价值？ 可以解决哪些问题？ 根据以上问题定位功能是否合理 UI功能 - 展示功能 模块关联-历史模块 新功能模块关联 考虑是否关联？耦合部分是否需要支持？ 客户使用场景-部署方式 网络特性 客户使用服务器常见外设 性能参数-性能要求 网卡最低速率 硬件支持 输出（提取最原始的测试需求） 需求分析： 分析依据（五维分析） 用户场景 功能是否和场景强关联 网络拓扑能否满足客户需求 和竞争对手比较差异 功能是否能满足客户实际应用场景 是否考虑了用户的实际操作 明确性 范围明确性（参数、类型长度范围） 清晰性限制等范畴 无法预知影响的需求提出进行确定，风险 二义性 概念模糊【大概念、第三方支持、与上个版本相同】 支持与不支持等范畴 一个需求描述能出现多种理解 完整性 需求一致性【用户需求、需求规格、需求矩阵三者是否同意】 需求完整【隐形需求】 关联性【与新老功能、与外置软件设备】 可测试性 实现测试需要的工具、方法【调试、接口命令】 定位方式【日志等形式观察】 复杂环境、容量边界、操作时过程不可见 输出 测试需求跟踪 缺陷预防bug 工具需求 整理出明确的需求点 测试地图 分析思路误区：需求和实现的区别【现有需求才有代码实现，不能把代码实现当作需求】 需求分析的意义 明确产品给客户带来的价值 明确产品支持和不支持的功能 明确产品各个功能的约束性 知道开发实现功能 知道测试分析和产出测试点 测试设计： - 测试分析： 我们需要做什么？ 把明确的需求点转换成测试项 缺陷预防 怎么做？ 整体模块分析 逻辑分析【这一点主要是从产品实现的原理上去分析可能的影响】 怎么做？ 开发的设计文档 补充和挖掘测试点 全部服务的异常监控、服务重启 各类存储对空间的占用、占满、是否需要做存储的接口测试 所有类型的管理员、操作权限测试、支持的多少管理员并发操作 对流程图的挖掘 – 流程图全部流程测试、流程图重要的节点异常测试 对状态的挖掘 – 所有状态的相互转化需要覆盖全、状态转化是否合理、每一个状态下哪些操作可做哪些不可做，多个状态是否可以共存 对关联项的挖掘 – 流程进展到哪一步关机重启/服务重启、和备份配置的关联，和操作日志的关联等等 任务的并发操作测试、是否可配置、是否会出现性能不足，是否符合用户场景 异常处理机制测试，异常处理机制是否完善 指标测试，开发的指标设计是否合理 修正不合理的需求 如何分析 逻辑原理： 该模块是否涉及到一些全新的概念(比如我们的 bbc 全量包)，需要明确? 该模块包括哪些服务? 该模块涉及到哪些存储技术(如 mysql、dap、redis)?具体怎么存储的?占用大小如何? 该模块的操作流程有哪些?是否有子流程图? 该模块是否有多个状态的转化?是否有明确的状态转化图? 该模块对多个管理员是否区分，管理员权限如何设计? 该模块是否有一些特殊的操作限制?操作限制是否有明确的表格? 该模块的任务是否有并发需求?并发的设计? 该模块的所有指标如何? 该模块是否有异常处理机制?在设备各种异常时，该模块的设计是否满足能稳健运行? 场景分析 从用户的使用习惯和使用方法去分析影响 检查当前案例是否覆盖到用户场景 关联测试分析： 考虑你的模块所在整个系统的地位，分析上下游的影响 对老功能的影响 经验补充分析 版本分析 模块分析 输出 测试项 补充测试地图 - 测试设计： 需要做什么？ 把测试项细化成测试点 缺陷预防 需要做什么？ 基本设计方法 等价类划分法【将输入域和输出域划分为不同的等价类，等价类之内的操作结果相同】，使用范围：显示输入框输入 边界值法【需要结合等价类划分法方法，在划分出来的等价类选取有代表性的值】 正反对比【一般会放到同一个用例里覆盖】 字符多样性【考虑不同字符的输入】 测试类型 产品专项测试 正交组合设计【正交矩阵，覆盖各个参数间的组合情况】 业务逻辑设计【根据业务设计测试点】 输出： 基本测试点 - 用例设计： 需要做什么？ 把测试点用文字完整表述出来 怎么做？ 功能用例框架： 模块框架模板 需求类 UI测试【如果UI用例可以被功能用例覆盖，这里可以不写】 公共测试类： 链接 选中会有高亮显示 点击跳转到对应页面 当前页面对应的名称下有区别显示 翻页 按钮 输入框【这个功能用例一般可以覆盖】 下拉框 排序 条目选择【这个很重要，第一次集成测试一定要保证每个选项都是有效的】 搜索 所有字符类型验证 为空验证 模糊搜索 精确搜索 搜索不存在的关键词 刷新 验证自动刷新 验证手动刷新 验证持续刷新 拖动 移动 点击下移，往下移动一行 点击上移，往上移动一行 最上面的行，上移不能点击，图标灰色 最下面的行，下移不能点击，图标灰色 功能测试 测试点： 功能基本流程逻辑覆盖 业务流程多样性覆盖 用户操作习惯的多样性 模块配置的多样性 数据流的多样性覆盖 测试目录 平级分类相对独立 上下级分类有关联 下级从上级细化而来 关联类： 模块与模块之间的 模块与功能之间 模块与硬件之间 场景类 建模思路 部署方式【比如用户一般使用2主机还是3主机部署集群】 数据流 业务流【用户是怎么使用申请工单，是怎么样的完整流程】 操作顺序【创建云主机的顺序之类的】 配置方法【用户一般怎么配置使用静态路由】 使用时间【用户会不会连续长时间开启云主机】 用户角色【一般那些角色做什么操作】 用户操作的设计方向 最常用的功能 最容易出现网上问题的功能 典型客户使用的功能 版本的性能验证 专项类 兼容性 可靠性【测试产品在异常情况下能否正常工作或者是恢复正常工作，可靠性重点测试对模块自身处理的覆盖】. 补充：容错性测试【测试系统在非正常操作、非正常的外部环境下是否能够处理错误和正常运行】 eg： 针对数据库的测试：【磁盘空间不足、数据库文件损坏、无读写数据权限、写数据时断电、写数据时强制关闭mysql、读写速度】 针对网络设备：【网络中有攻击数据、丢包时延大、IP冲突、网络线路断开、同时掉电】 针对程序：【 客户端进程被手动停止、设备后台资源cpu、内存占满】 安全性【主要是验证程序有哪些缺陷可能会造成安全方面的问题】 eg： 密码加密方式【什么时候用明文，什么时候用密码显示】 隐私数据隐藏【用户的隐私显示】 设备的完整目录【完整的目录会增加后台被攻击的危险】 文件上传功能【检查上传的文件类型；限制上传文件的权限】 防暴力破解【对于连线认证之类的操作要冻结、禁用其连续错误尝试操作】 脚本测试 使用注意细节 文件夹以01-xx，02-xx区分开 每个文件夹下不能超过10个用例 每个测试用例一个测试点 在02-功能测试的描述中，备注说明功能测试框架的思路 - 用例整体规范： 用例标题【好的标题需要准确的表达你的测试目的、要测试的测试点】 eg： 测试。。。 验证。。。 。。。的测试 与。。。的关联测试 。。。的异常测试 。。。的兼容性测试 用例属性 测试环境【默认的前置条件可以不用写；写的前置条件要准确，不要写的模糊】 测试方法 优先级 BVT【最最最基本的功能】-BVT(10%)：模块最基本的功能验证(含常用部署、基本关联)，推荐1级用例的20%左右 level1【基本操作、基本场景】-Leve1(30%)：基本需求点，基本逻辑，基本可靠性，基本关联，基本用户场景 level2【比较少见的正常操作】-Leve2(40%)：常见功能/逻辑细化点/专项细化点，常见关联/容错/边界值/用户场景 level3【异常操作；后续不需要再执行】-Leve3(20%)：错误提示、极少测试的用例、非常见部署方式/用户场景/容错/边界值等 用例格式 前置条件 测试步骤【单个用例全部步骤不能超过8步】 后置条件【不是必填的】 预期结果 备注【不是必填的】 语言规范 语言简练 不能出现模糊的形容词【比如说大概、可能、很多、差不多】 可维护性 灵活运用模块备注 设计原则 目的明确【一个用例对应一个测试点；测试步骤和测试目的一致】 用例效率 保证设计出来的用例10分钟内可以执行完成； 用例需要的环境可以整理出来，然后写到模块备注中，让执行者先准备好环境一次性执行全部用例； 执行的时候按照测试集方式来执行； 有工具可以实现的用例不要采用脚本方式实现 测试步骤： 用户角度 设计的用例要符合用户的操作顺序和操作习惯 符合用户的使用环境 符合用户的配置 可执行 不要出现那种用例设计没有错，但是执行起来很复杂或者是依赖环境很夸张的用例 正反对比 这一点很重要，很多时候我们会把有正反操作的用例分开写，其实是可以合在一个用例里面写 强弱关联 对于强关联的步骤一定要写清楚 对于弱关联的可以备注或者是不写 测试用例不能出现操作步骤 直接写需要做的操作就可以了 预期结果： 用户角度： 反思用户期望操作完会有什么结果 反思客户最关注的测试点 可检查 预期结果要可以观察到，不要写的很模糊 把重点检查的检查点覆盖到 用例编写口诀 强弱正反之业务 重点突出之效率 目的明确之语言 框架覆盖之检查 逻辑场景之经验 ","link":"https://liujinyang6.github.io/post/ruan-jian-ce-shi-liu-cheng/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://liujinyang6.github.io/post/hello-gridea/"},{"title":"Hadoop+Zookeeper+Spark+Hbase大数据平台搭建","content":"Posted on 2018-06-10 | In Hexo 前言 随着这学期对于hbase和spark的学习，加上上学期学习的hadoop知识，这次专周在这一年学习的基础上，使用虚拟机或者实机&gt;搭建一个伪分布式大数据平台，涉及hadoop平台、hbase平台还有spark平台，使用一台虚拟机充当主节点master，两台虚拟机&gt;充当子节点slave、slave1。 前期准备 hadoop-2.7.6.tar.gz hbase-1.2.6-bin.tar.gz jdk-8u161-linux-x64.tar.gz zookeeper-3.4.10.tar.gz sqoop-1.99.7.tar.gz spark-2.2.1-bin-hadoop2.7.tgz kafka_2.11-1.1.0.tgz 修改hostname 在root用户下的主界面运行一下命令： $ vim /etc/hostname 将localhost修改为姓名缩写和学号后四位然后:wq保存退出。 在每个节点/etc/hosts中加入本机ip和其他节点ip 在root用户下的主界面运行一下命令： $ vim /etc/hosts 添加以下内容： 127.0.0.1 localhost 10.19.2.197 ljy0326 10.19.2.209 pxc0305 10.19.1.242 huwei0303 必须保证hosts内每个ip对应的主机名与hostname一致 配置免密登录 代码如下： $ sudo apt-get install ssh $ ssh-keygen -t rsa $ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys $ sudo gedit authorized_keys $ ssh huwei0303 添加完成，效果如图： 下载资源 下载JDK 请登录如下网站，下载你想要的版本http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk8-downloads-2133151-zhs.html 下载Hadoop等其他安装包 https://mirrors.tuna.tsinghua.edu.cn/apache/ 需要下载 Hadoop、HBase、Spark、Scala、Sqoop、kafka、Zookeeper 解压文件 解压命令： tar -zxvf ****.gz -C /opt/文件夹名 将jdk1.8.0_144文件夹更名为java 将hadoop-2.6.7 文件夹更名为hadoop 其余文件夹同上。 在每个节点配置环境变量 执行以下命令： $ vim /etc/profile 在文件最后输入以下内容： export JAVA_HOME=/opt/java export HADOOP_HOME=/opt/hadoop export ZOOKEEPER_HOME=/opt/zookeeper export HBASE_HOME=/opt/hbase export SPARK_HOME=/opt/spark export SCALA_HOME=/opt/scala export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf:$HBASE_HOME/bin:$SPARK_HOME/bin:$SCALA_HOME/bin:$SQOOP_HOME/bin 配置如图： 保存退出后需使环境变量生效，执行以下命令： $ source /etc/profile 然后生效后运行java -version查看jdk配置是否成功 在每个节点创建文件夹并改权限 该文件夹为Hadoop相关文件夹 创建命令： $ mkdir -p /opt/hadoop 将主节点设置为NTP服务器 一个Hadoop集群就是一个小型局域网，我们需要设定一台NTP服务器作为整个网络的标准时间参考，使用网络（集群）内的所有机器保持时间一致！以下是详细的操作步骤： 安装ntp软件 执行命令： $ apt-get install ntp 修改配置文件 打开文件需要修改的配置文件,执行以下命令： $ vim /etc/ntp.conf # Specify one or more NTP servers server 127.127.1.0 因为是内网，所以用本地时间做为服务器时间，注意这里不是127.0.0.1 在配置文件里找到以下4条并注释掉: #server 0.ubuntu.pool.ntp.org #server 1.ubuntu.pool.ntp.org #server 2.ubuntu.pool.ntp.org #server 3.ubuntu.pool.ntp.org 增加了NTP服务器自身到时间服务器的同步 fudge 127.127.1.0 stratum 8 增加了一些需要同步的客户端的ip restrict -4 default kod notrap nomodify nopeer noquery limited restrict -6 default kod notrap nomodify nopeer noquery limited restrict 10.19.2.209 restrict 10.19.1.242 配置完成如图： 配置Hadoop 配置 hadoop-env.sh # The java implementation to use. 修改为自己的JAVA_HOME路径 export JAVA_HOME=/opt/java/jdk-8u171-linux-x64 配置hdfs-site.xml 配置如图： 配置core-site.xml 配置如图： 配置mapred-site.xml 配置如图： 配置slaves 添加节点的主机名： ljy0326 pxc0305 huwei0303 添加完毕后保存退出。 配置 yarn-site.xml 如图： 配置JournalNode JournalNode的配置是在hdfs-site.xml文件中， 打开文件： $ vim hdfs-site.xml 在原有的配置下面添加一下内容，需保证所有的内容均在 &lt;!--指定hdfs的nameservice为ljy0326，需要和core-site.xml中的保持一致--&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ljy0326&lt;/value&gt; &lt;/property&gt; &lt;!-- ns下面有两个NameNode，分别是nn1，nn2--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ljy0326&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!--配置 nn1的RPC通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ljy0326.nn1&lt;/name&gt; &lt;value&gt;ljy0326:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置nn1的http通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ljy0326.nn1&lt;/name&gt; &lt;value&gt;ljy0326:50070&lt;/value&gt; &lt;/property&gt; &lt;!--配置 nn2的RPC通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ljy0326.nn2&lt;/name&gt; &lt;value&gt;pxc0305:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置nn2的http通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ljy0326.nn2&lt;/name&gt; &lt;value&gt;pxc0305:50070&lt;/value&gt; &lt;/property&gt; &lt;!--指定NameNode的元数据在JournalNode上的存放位置--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://ljy0326:8485;pxc0305:8485;huwei0303:8485/ljy0326&lt;/value&gt; &lt;/property&gt; &lt;!--指定JournalNode在本地磁盘存放数据的位置--&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/journal&lt;/value&gt; &lt;/property&gt; &lt;!--开启NameNode故障时自动切换--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!--配置失败自动切换实现方式--&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ljy0326&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyPrivider&lt;/value&gt; &lt;/property&gt; &lt;!--配置隔离机制，如果ssh是默认22端口，value直接写sshfence即可--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence(ljy0326:22)&lt;/value&gt; &lt;/property&gt; &lt;!--使用隔离机制时需要ssh免登陆--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; 将配置好的文件发送到其他节点: 运行shell命令: $ scp –r /opt/java/jdk root@huwei0303:/opt/java $ scp –r /opt/java/jdk root@pxc0305:/opt $ scp –r /opt/hadoop/hadoop-2.6.7 root@huwei0303:/opt/hadoop $ scp –r /opt/hadoop/hadoop-2.6.7 root@pxc0305:/opt/hadoop 格式化namenode 在master节点运行shell命令: $ hadoop namenode –format 提示0，则格式化正常 启动hadoop集群 运行命令： $ /sbin/start-all.sh 输入命令jps，hadoop启动成功如图： 配置ZooKeeper 创建相关文件 $ sudo mkdir -p /usr/local/zkData //该文件夹为Zookeeper数据文件夹 $ mkdir -p /opt/zookeeper/logs //该文件夹存放Zookeeper 日志文件 在ljy0326节点运行shell命令: $ echo 1 &gt;&gt; /usr/local/zkData/myid 在pxc0305 节点运行shell命令 $ echo 2 &gt;&gt; /usr/local/zkData/myid 在huwei0303 节点运行shell命令 $ echo 3 &gt;&gt; /usr/local/zkData/myid 配置/opt/zookeeper/conf/zoo.cfg # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. # 将此处改为原先创建好的目录 dataDir=/usr/local/zkData # the port at which the clients will connect clientPort=2181 server.1=0.0.0.0:2888:3888 server.2=pxc0305:2888:3888 server.3=huwei0303:2888:3888 配置完成如图： 注意此处（3个虚拟机要分别配置） 在pxc0305节点，将此处配置为 server.1=ljy0326:2888:3888 server.2=0.0.0.0:2888:3888 server.3=huwei0303:2888:3888 在huwei0303节点，将此处配置为 server.1=ljy0326:2888:3888 server.2=pxc0305:2888:3888 server.3=0.0.0.0:2888:3888 配置/opt/zookeeper/bin/zkEnv.sh 找到 if [ &quot;x${ZOO_LOG_DIR}&quot; = &quot;x&quot; ] then ZOO_LOG_DIR=&quot;.&quot; fi 将.改为/opt/zookeeper/logs 将配置文件发送到其他节点 运行shell命令： $ scp –r /opt/zookeeper/ root@pxc0305:/opt $ scp –r /opt/zookeeper/ root@huwei0303:/opt 启动Zookeeper集群 在每个节点运行shell命令: $ zkServer.sh start 配置HBase 配置hbase-env.sh export JAVA_HOME=/opt/java/jdk //更改Java环境变量 配置hbase-site.xml &lt;configuration&gt; &lt;property&gt; //集群中所有RegionServer共享目录 &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://ljy0326:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //集群的模式 &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; // zookeeper集群的URL配置 &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;ljy0326,pxc0305,huwei0303&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //指定ljy0326 &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;ljy0326&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //客户端与zookeeper的连接端口 &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //客户端与zookeeper的通讯超时时间 &lt;name&gt;zookeeper.session.timeout.ms&lt;/name&gt; &lt;value&gt;1800000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; // RegionServer处理IO请求的线程数 &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //RegionServer发生Split的阔值 &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt; &lt;value&gt;2147483648&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置regionservers pxc0305 huwei0303 将配置文件发送到其他节点 $ scp –r /opt/hbase/ root@pxc0305:/opt $ scp –r /opt/hbase/ root@huwei0303:/opt 在master节点启动HBase $ start-hbase.sh 输入命令jps，Hbase启动成功如图： 搭建spark 在每个节点创建Spark相关目录: $ sudo mkdir –p /usr/local/spark //该目录用于存放worker信息和日志 配置spark-env.sh文件 配置如图： #在配置slave节点时，将SPARK_LOCAL_IP改为对应的IP地址或者Hostname 配置spark-defaults.conf 配置如图： 配置slaves #在文件中加入配置信息 pxc0305 huwei0303 将配置文件发送到其他节点 运行shell命令： $ scp –r /opt/spark/ root@pxc0305:/opt $ scp –r /opt/spark/ root@huwei0303:/opt $ scp –r /opt/scala/ root@pxc0305:/opt $ scp –r /opt/scala/ root@huwei0303:/opt 启动Spark集群 #在Hadoop集群启动的情况下运行以下命令: $ /opt/spark/spark-2.2.1/sbin/start-all.sh 搭建kafka 创建kafka相关目录 $ mkdir /opt/kafka/logs //存放kafka消息的目录，也可以使用默认的目录 修改配置文件 $ vim /opt/kafka/ kafka_2.11-1.1.0 /config/server.properties 需要修改的部分: broker.id=1 //当前机器在kafka机器里唯一标识，与zookeeper的myid相匹配 log.dirs=/opt/kafka/logs //存储消息的目录位置 将配置文件发送到其他节点 运行shell命令: scp –r /opt/spark/ root@pxc0305:/opt scp –r /opt/spark/ root@huwei0303:/opt 切换到pxc0305和huwei0303上修改配置文件: [root@pxc0305]# vim server.properties broker.id=2 [root@ huwei0303]# vim server.properties broker.id=3 启动kafka集群 保证先启动zookeeper集群 然后在每个节点的、kafka/sbin目录下运行 $ cd /opt/kafka/ kafka_2.11-1.1.0/sbin $ ./kafka-server-start.sh -daemon ../config/server.properties 若成功启动，输入jps可以看到 kafka 搭建sqoop1.99.7 配置第三方jar引用路径 $ vim /etc/profile $ export SQOOP_SERVER_EXTRA_LIB=$SQOOP_HOME/extra 最后把mysql的驱动jar文件复制到这个目录下。 配置sqoop.properties文件 org.apache.sqoop.submission.engine.mapreduce.configuration.directory=/opt/hadoop/etc/hadoop org.apache.sqoop.security.authentication.type=SIMPLE org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.SimpleAuthenticationHandler org.apache.sqoop.security.authentication.anonymous=true 验证配置是否有效 使用bin中的sqoop2-tool工具进行验证： $ bin/sqoop2-tool verify 这个工具也可用于软件升级。若没有什么问题，往下走。 启动sqoop $ bin/sqoop2-server start 安装mysql 在ljy0326上运行命令 $ apt-get install mysql-server-5.6 会提示设置root密码，设置完成则运行查看是否成功 检测搭建是否完成 搭建成功后每个节点jps运行截图： 结果如上图，大功告成！ ","link":"https://liujinyang6.github.io/post/hadoopzookeepersparkhbase-da-shu-ju-ping-tai-da-jian/"},{"title":"Github Pages+Hexo+腾讯云域名绑定","content":"Github Pages+Hexo+腾讯云域名绑定 Posted on 2018-05-14 | In Hexo Github Pages Github Pages可以免费托管，所以把博客托管到github上。 首先，创建一个github仓库，仓库的命名格式为：yourusername.github.io，然后根据提示进行下一步。 hexo搭建博客 本博客中使用了next的主题，所以会详细介绍下按照next主题搭建的步骤。 准备工作 1.首先要安装下node.js（官网下载）,如果已经安装可以跳过。 2.安装git（官网下载）。 3.安装Hexo： $ npm install -g hexo 安装成功后，使用version命令查看是否安装成功 $ hexo version 4.本地静态hexo博客 新建一个文件夹，作为你博客文件的根目录 命令行进入该文件夹下,输入以下命令，生成模板： $ hexo init 模板生成后，输入以下命令： $ npm install 最后可以运行hexo s命令查看是否搭建成功 下载主题 在 themes 文件夹内，新增一个next文件夹，并修改_config.yml 内的 theme 设定theme: next，即可切换到next主题。然后把next主题的内容clone到刚刚新建的next文件夹下: git clone https://github.com/liuJinYang6/hexo-theme-next.git themes/next 配置博客 1.用户信息配置 根据个人需求进行相关配置。 注意：在themes/next目录中的_config.yml中配置一下信息，而非博客根目录下的_config.yml中配置。ps:不过我的有些没起作用的就放到了根目录下的_config.yml中。 2.创建About页面 在根目录下的source文件夹里创建一个about文件夹，然后在about文件夹里新建index.md文件,在文件中添加如下代码，并保存： --- title: 关于我 date: 2016-10-10 15:40:19 --- 具体介绍信息根据个人进行添加。 部署Hexo博客 建站 $ hexo init yourname $ cd yourname $ npm install 配置_config.yml的部署: deploy: type: git repository: git@github.com:liuJinYang6/liuJinYang6.github.io.git branch: master 清理缓存 $ hexo clean 生成静态网页 $ hexo g 本地查看效果，执行完后可以通过http://localhost:4000查看本地效果 $ hexo s 部署到git $ hexo d 绑定腾讯云域名 之前在腾讯云买了域名，域名购买成功之后要等待实名认证。 添加CNAME文件 在根目录下的source文件夹下新建CNAME文件，没有后缀。打开CNAME文件，在里面添加你的域名信息，保存之后，重新部署到github pages上。 给github项目添加 在项目的Settings中，添加Custom domain到自己的域名。 给域名添加解析记录 1.ping你自己的yourname.github.io获取到ip地址； 2.打开域名的解析列表，添加两条解析记录； 更换之后，可能需要等一段时间才能生效，差不多就大功告成啦。 ","link":"https://liujinyang6.github.io/post/github-pageshexoteng-xun-yun-yu-ming-bang-ding/"}]}