{"posts":[{"title":"Appium教程","content":"一、Appium介绍 Appium是一款开源的自动化测试工具，其支持 iOS和安卓平台上的原生的，基于移动浏览 器的，混合的应用。 1、 使用 Appium进行自动化测试的好处 ​ Appium在不同平台中使用了标准的自动化 APIs，所以在跨平台时，不需要重新编译或者 修改自己的应用。 ​ Appium支持 Selenium WebDriver支持的所有语言，如 java、Object-C、JavaScript、Php、 Python、Ruby、C#、，或者 Perl 语言，更可以使用 Selenium WebDriver 的 Api。Appium支持任何一种测试框架。Appium实现了真正的跨平台自动化测试。（本文主要介绍 Python的用法） 2、Appium架构 ​ Appium 是一个用 Node.js编写的HTTP server，它创建、并管理多个 WebDriver sessions 来 和不同平台交互，如 iOS ，Android 等等. ​ Appium 开始一个测试后，就会在被测设备（手机）上启动一个 server ，监听来自 Appium server的指令. 每种平台像 iOS 和 Android 都有不同的运行、和交互方式。所以 Appium 会用某个桩程序“侵入”该平台，并接受指令，来完成测试用例的运行。 二、Appium安装 1、安装JDK，配置JDK 环境 打开计算机-&gt;系统属性-&gt;高级系统设置-&gt;环境变量-&gt;新建（系统变量），如图所示： ","link":"https://liujinyang6.github.io/post/appium-jiao-cheng/"},{"title":"DDT框架","content":"​ ​ 数据驱动的单元测试是为数据源中的每一行重复运行的一种单元测试。数据驱动的单元测试的常用情况是使用多个输入值测试 API。不是编写调用 API 的多个单元测试（每个单元测试均具有一组新的输入），也不是在单元测试中创建一个数组并使用循环代码，而是可以编写执行 API 的单个单元测试方法。然后可以从数据库表的行中进行数据检索以便传递给该测试方法的连续调用。可以使用此技术测试由不同用户（每个用户具有不同角色）使用的应用程序。对于每个用户，数据源中的一行将根据角色指示预期响应。然后，该测试将通过针对每个用户运行功能，对该应用程序进行测试，并验证产生的响应是否与预期响应一致。 ​ 在测试工作中，针对某一API接口，或者某一个用户界面的输入框，需要设计大量相关的用例，每一个用例包含实际输入的各种可能的数据。通常的做法是，将测试数据存放到一个数据文件里，然后从数据文件读取，在脚本中循环输入测试数据，并对结果进行验证。 ​ ddt是结合unittest框架来工作的，所以要先具备unittest框架的知识。 使用步骤 1.导入ddt包 2.用装饰器装饰@ddt 3.传入参数，执行 传参示例 传参方式一：单个传参 # 单个传参 import unittest from ddt import ddt,data,unpack @ddt class MyTestCase1(unittest.TestCase): # 2,3,4会分别按照执行次数传入，比如第一次执行方法传入2，第二次执行方法传入3,第三次...... @data(2, 3, 4) def test_normal(self, value): print(value) self.assertEqual(value, 2) if __name__ == '__main__': unittest.main() 传参方式二：元组、列表、字典传参 # 元组、列表、字典传参 import unittest from ddt import ddt,data,unpack @ddt class MyTestCase2(unittest.TestCase): # 会依次按照执行次数传入，比如第一次执行该方法传入（1，2），第二次传入（2，3） @data((1, 2), (2, 3)) @unpack # 只有需要进行分发参数的时候才需要添加。1分发给value1，2分发给value2 def test_tuple(self, value1, value2): print(&quot;tuple:&quot;,value1, value2) self.assertEqual(value2, value1+1) @data([1, 2], [2, 3]) @unpack def test_list(self, value1, value2): print(&quot;list:&quot;,value1, value2) self.assertEqual(value2, value1+1) @data({'value1':1, 'value2':2}, {'value1':2, 'value2':3}) @unpack # 入参参数名必须和字典key值一致，否则会报错 def test_dict(self, value1, value2): print(&quot;dictionary:&quot;,value1, value2) self.assertEqual(value2, value1+1) if __name__ == '__main__': unittest.main() 传参方式三：json文件传参 # 传入json import unittest from ddt import ddt,data,unpack,file_data @ddt class MyTestCase3(unittest.TestCase): @file_data('E:\\\\test.json') def test_file(self, value): print(&quot;json file:&quot;,value) if __name__ == '__main__': unittest.main() ","link":"https://liujinyang6.github.io/post/ddt-kuang-jia/"},{"title":"unittest教程","content":"Python中有一个自带的单元测试框架是unittest模块，用它来做单元测试，它里面封装好了一些校验返回的结果方法和一些用例执行前的初始化操作。在说unittest之前，先说几个概念： TestCase 也就是测试用例 TestSuite 多个测试用例集合在一起，就是TestSuite TestLoader是用来加载TestCase到TestSuite中的 TestRunner是来执行测试用例的,测试的结果会保存到TestResult实例中，包括运行了多少测试用例，成功了多少，失败了多少等信息 下面我们分别来解释这四个概念的意思，先来看一张unittest的静态类图。 一个TestCase的实例就是一个测试用例。什么是测试用例呢？就是一个完整的测试流程，包括测试前准备环境的搭建(setUp)，执行测试代码(run)，以及测试后环境的还原(tearDown)。单元测试(unit test)的本质也就在这里，一个测试用例是一个完整的测试单元，通过运行这个测试单元，可以对某一个问题进行验证。 而多个测试用例集合在一起，就是TestSuite，而且TestSuite也可以嵌套TestSuite。 TestLoader是用来加载TestCase到TestSuite中的，其中有几个loadTestsFrom__()方法，就是从各个地方寻找TestCase，创建它们的实例，然后add到TestSuite中，再返回一个TestSuite实例。 TextTestRunner是来执行测试用例的，其中的run(test)会执行TestSuite/TestCase中的run(result)方法。 测试的结果会保存到TextTestResult实例中，包括运行了多少测试用例，成功了多少，失败了多少等信息。 一个class继承了unittest.TestCase，便是一个测试用例，但如果其中有多个以 test 开头的方法，那么每有一个这样的方法，在load的时候便会生成一个TestCase实例，如：一个class中有四个test_xxx方法，最后在load到suite中时也有四个测试用例。 在每一个测试用例中可以重写 以下函数 : setUp()该测试用例执行前的设置工作、 tearDown()该测试用例执行后的清理工作、 setUpClass()所有测试用例前的设置工作、 tearDownClass()所有测试用例执行后的清洗工作 在每一个测试用例中可以通过skip，skipIf，skipUnless装饰器跳过某个测试函数，或者用TestCase.skipTest方法跳过测试函数。 @unittest.skip() @unittest.skipIf() @unittest.skipUnless() 到这里unittest的整个流程就清楚了： 写好TestCase，然后由TestLoader加载TestCase到TestSuite，然后由TextTestRunner来运行TestSuite，运行的结果保存在TextTestResult中。 我们通过命令行或者unittest.main()执行时，main会自动调用TextTestRunner中的run来执行，或者我们可以直接通过TextTestRunner来执行用例。 加个说明： 1、TestLoader加载TestCase到TestSuite可以通过TestSuite实例对象的addTest()和addTests()方法向suite中添加case或suite 2、在Runner执行时，默认将执行结果输出到控制台，我们可以设置其输出到文件，在文件中查看结果（你可能听说过HTMLTestRunner，是的，通过它可以将结果输出到HTML中，生成漂亮的报告，它跟TextTestRunner是一样的，从名字就能看出来，这个我们后面再说）。 3、在进行测试时可以传递verbosity参数，用以控制执行结果的输出，0 是简单报告、1 是一般报告、2 是详细报告。 被测方法： 这里我们随意写几个业务函数，表示我们将要进行测试的功能函数。将功能函数文件存储成myfun.py # 被测函数示例 # 保存为mufun.py def add(a, b): return a + b def minus(a, b): return a - b def multi(a, b): return a * b def divide(a, b): return a / b TestCase测试用例: 我们通过测试用例用代码来实现每一个测试的详细过程和针对测试目标要测试的内容。同目录下创建test_myfun.py # 测试用例示例 class TestMyFun(unittest.TestCase): # TestCase基类方法，所有case执行之前自动执行 @classmethod def setUpClass(cls): print(&quot;这里是所有测试用例前的准备工作&quot;) # TestCase基类方法，所有case执行之后自动执行 @classmethod def tearDownClass(cls): print(&quot;这里是所有测试用例后的清理工作&quot;) # TestCase基类方法，每次执行case前自动执行 def setUp(self): print(&quot;这里是一个测试用例前的准备工作&quot;) # TestCase基类方法，每次执行case后自动执行 def tearDown(self): print(&quot;这里是一个测试用例后的清理工作&quot;) @unittest.skip(&quot;我想临时跳过这个测试用例&quot;) def test_add(self): # 测试add()函数 self.assertEqual(3, add(1, 2)) self.assertNotEqual(3, add(2, 2)) def test_minus(self): # 测试minus()函数 self.skipTest(&quot;跳过这个测试用例&quot;) self.assertEqual(1, minus(3, 2)) def test_multi(self): # 测试multi()函数 self.assertEqual(6, multi(2, 3)) def test_divide(self): # 测试divide()函数 self.assertEqual(2, divide(6, 3)) self.assertEqual(2.5, divide(5, 2)) if __name__ == &quot;__main__&quot;: unittest.main(verbosity=2) 注意： skip装饰器一共有三个 unittest.skip(reason)、unittest.skipIf(condition,reason)、unittest.skipUnless(condition,reason)，其中skip是无条件跳过，skipIf是当condition为True时跳过，skipUnless是当condition为False时跳过。 每个测试方法必须以 test 开头，否则是不被unittest识别的。其实每一个test开头的方法都会加载为独立的测试用例。 在unittest.main()中加 verbosity 参数可以控制输出的错误报告的详细程度，默认是 1；如果设为 0，则不输出每一用例的执行结果；如果参数为2则表示输出详细结果。 TestSuite测试套件 TestSuite用来控制多个测试用例和多个测试文件之间的测试顺序。（这里的示例中的几个测试方法并没有一定关系，但之后你写的用例可能会有先后关系，需要先执行方法A，再执行方法B），我们添加到TestSuite中的case是会按照添加的顺序执行的。 一、创建测试套件 语法：1.实例化、2.调用 addTest()方法 # 1.实例化Testsuite类 # 注：TestSuite()主要用来创建测试套件集合 suite = unittest.TestSuite() # 2.调用addTest()添加测试方法 # 添加语法：suite.addTest(文件名.类名(‘类中的方法名’)) suite.addTest(TestCount('test_add')) # 调用TestSuite类中的addTest：suite.addTest(类名(‘类中的方法名’)) # 执行顺序是按照添加的顺序执行，先添加的先执行 注：test_add是unittest脚本中的被测方法，如果是添加被导入模块中的方法，则需要指定哪个文件名。 suite.addTest(文件名.类名(‘类中的方法名’)) 二、 运行测试套件TextTestRunner() 语法：1.实例化、 2.调用run()方法 # 1.实例化TextTestRunner类 runner = unittest.TextTestRunner() # 2.调用Testsuite类中的addTest方法 runner.run(suite) 注：TextTestRunner()主要用来运行测试套件 坑：使用Unittest做单元测试，addTest（）单个case的时候却执行全部的case 首先造成这个结果的原因是pycharm配置问题 测试代码： import unittest class Testadd(unittest.TestCase): def setUp(self): self.a = 20 self.b = 10 def test_add(self): result = self.a + self.b self.assertEqual(result,30) def test_sub(self): result = self.a -self.b self.assertEqual(result,10) if __name__ == &quot;__main__&quot;: suite = unittest.TestSuite() suite.addTest(Testadd(&quot;test_add&quot;)) runner = unittest.TextTestRunner() runner.run(suite) pycharm执行结果： 命令行执行结果： 问题解决： 点击pycharm的右上角下拉菜单，点击Edit configurations 将Python tests里的对应文件的py.test for...或者unittest for...的文件删除（选中后点击左上角的减号） 点击+，在下拉菜单中选择Python，然后在右边的script path里...选中所要运行的文件 最后点击ok即可，再在所要运行的文件处（最好是main处）点击右键就会发现run unittest变成了run 再次在pycharm中运行，well done 总结： 执行unittest in demoSingle就会运行全部case 而如果运行py文件本身就会只运行addsuite添加的用例 三、单元测试框架实现模块整合---discover方法 遍历所有测试脚本实现整合 使用测试套件单独管理全部功能的用例，利用测试套件整合 TestLoader 该类根据各种标准负责加载测试用例，并返回给测试套件。正常情况下没有必要创建这个类的实例。unittest 提供了可以共享了 defaultTestLoader 类，可以使用其子类和方法创建实例，所以我们可以使用其下面的 discover()方法来创建一个实例。 既： discover = unittest.defaultTestLoader.discover(start_dir，pattern='test*.py'，top_level_dir=None) discover = unittest.TestLoader().discover(start_dir，pattern='test*.py'，top_level_dir=None) #运行方法同上(上述方法2选1) runner = unittest.TextTestRunner() runner.run(discover) 找到指定目录下所有测试模块，并可递归查到子目录下的测试模块，只有匹配到文件名才能被加载。 start_dir ：要测试的模块名或测试用例目录。（采用双斜线或目录前加r） pattern='test*.py'：表示用例文件名的匹配原则。星号“*”表示任意多个字符。 top_level_dir=None：测试模块的顶层目录。如果没顶层目录（也就是说测试用例不是在该目录下则需要分别指定），默认为 None。 注：discover发现的py文件不能控制先后顺序，只能通过文件名字的assccii码值来判断先后运行顺序，所以文件命名的时候可以通过testA……等来定义 总结：单元测试的执行方法一共有3种： 第一种：通过unittest.main()加载全部test开头的用例并自动执行 第二种：通过添加测试套件的方法addTest，然后运行添加好的测试套件 第三种：通过testloader来加载指定目录下的test开头的用例，运行添加好的discover 测试报告 1、通过打开/写入文件，编写测试报告 ​ 自己完成 2、通过 HTMLTestRunner.py 来生成测试报告。 HTMLTestRunner 是 Python 标准库的 unittest 单元测试框架的一个扩展。它生成易于使用的 HTML 测试报告。 HTMLTestRunner是在 BSD 许可证下发布。 HTMLTestRunner 首先要下 HTMLTestRunner.py 文件，下载地址： http://tungwaiyip.info/software/HTMLTestRunner.html HTMLTestRunner.py 本是一个.py 文件，将它放到 Python 安装目录下即可调用。 # 语法： # 首先引入HTMLTestRunner包 import HTMLTestRunner # 用法： # 1----------定义个报告存放路径 filename = 'C:\\\\test_object\\\\report\\\\result.html' # 2----------定义一个文件名，以写方式打开 fp = open(filename, 'wb') # 3----------定义测试报告 runner =HTMLTestRunner.HTMLTestRunner( stream=fp, title=u'百度搜索测试报告', description=u'用例执行情况：') # 4----------运行测试用例 runner.run(suite) # 5----------关闭报告文件 fp.close() ","link":"https://liujinyang6.github.io/post/unittest-jiao-cheng/"},{"title":"python读写excel文件","content":"用xlrd和xlwt读写excel 首先下载安装xlrd和xlwt这两个库 使用xlrd读取excel # 导入包 import xlrd # 1、打开excel readbook = xlrd.open_workbook(r'\\test\\canying.xlsx') # 2、获取读入的文件的sheet sheet = readbook.sheet_by_index(1)#索引的方式，从0开始 sheet = readbook.sheet_by_name('sheet2')#通过名字定位sheet页 allsheetnames = readbook.sheet_names()#返回所有sheet页名字组成的列表 # 3、获取sheet的最大行数和列数 nrows = sheet.nrows#行 ncols = sheet.ncols#列 # 4、获取某个单元格的值 lng = sheet.cell(x,y) lng = sheet.cell(0,0).value#获取1行1列的表格值，从0开始计数 lat = sheet.cell(1,4).value#获取2行5列的表格值，从0开始计数 # 5、获取某行/某列的值 row_value = sheet.row_values(x) #获取x行的值，从0开始计数 col_value = sheet.col_values(y) #获取y列的值，从0开始计数 使用xlutils.copy写excel # 导入前，先导入xlrd，需要依赖这个包 from xlutils.copy import copy # 1-读取源excel中的所有数据（复制对象） rb = xlrd.open_workbook(excel_dir + '\\\\' + 'data.xls') # 2-复制读取的源excel对象 wb = copy(rb) # 3-通过get_sheet()获取复制对象的sheet页 ws = wb.get_sheet(2) # 4-对sheet页进行写入(传入x和y坐标，和具体写入的value) ws.write(id,2,real) ws.write(id,3,status) # 5-保存excel（具体的excel路径+名称） wb.save(self.excel_dir + '\\\\' + 'data.xls') 注意：运行代码时要关闭excel，否则会报错 使用openpyxl库读写excel ​ xlrd和xlwt处理的是xls文件，单个sheet最大行数是65535，如果数据量超过65535就会遇到：ValueError: row index was 65536, not allowed by .xls format。 ​ 如果有更大需要的，建议使用openpyxl函数，最大行数达到1048576。 # 导入包 import openpyxl # 打开excel file_path = r'D:\\work\\testdata.xlsx' inwb = openpyxl.load_workbook(file_path) # 读取文件 # 获取打开的excel的sheet内容 sheetnames = inwb.get_sheet_names() # 获取所有sheet页的name ws = inwb.get_sheet_by_name(sheetnames[0]) # 按照name获取第一个sheet页的内容 # 获取sheet的最大行数和列数 rows = ws.max_row cols = ws.max_column # 获取某个单元格的值 ws.cell(1, 1).value # 打开将写的表并添加sheet outwb = openpyxl.Workbook() # 打开一个将写的文件 outws = outwb.create_sheet(index=0) # 在将写的文件创建一个新的sheet # 保存 saveExcel = r'D:\\work\\new.xlsx' outwb.save(saveExcel) # 一定要记得保存 注意：最后一定要记得保存，否则就前功尽弃喽😲 ","link":"https://liujinyang6.github.io/post/python-du-xie-excel-wen-jian/"},{"title":"Python读取config.ini文件","content":"读取步骤： 1.导入configparser import configparser 2.实例化一个configparser对象，读取目标配置文件内容 # 1.实例化configparser对象 conf = configparser.ConfigParser() # 2.获取目标.ini文件路径 file_path = os.path.dirname(‘xxxini文件路径’)+&quot;\\\\config.ini&quot; # 3.读取目标文件内的内容(section)，当有中文的时候使用encoding conf.read(file_path,encoding=&quot;utf-8-sig&quot;) config.ini文件格式 获取文件内的所有section sections = conf.sections() print('获取配置文件所有的section', sections) 获取xx section下的所有option options = conf.options('mysql') print('获取指定section下所有option', options) 获取xx section下的所有键值对 items = conf.items('mysql') print('获取指定section下所有的键值对', items) 获取xx section下的某个option value = conf.get('mysql', 'host') print('获取指定的section下的option', value) ","link":"https://liujinyang6.github.io/post/python-du-qu-config-ini-wen-jian/"},{"title":"常用的邮箱服务器","content":"一、常用的邮箱服务器地址 阿里云邮箱（mail.aliyun.com）: POP3服务器地址:pop3.aliyun.com（SSL加密端口：995；非加密端口：110） SMTP服务器地址:smtp.aliyun.com（SSL加密端口：465；非加密端口：25） IMAP服务器地址：imap.aliyun.com（SSL加密端口：993；非加密端口：143） 谷歌邮箱(google.com)： POP3服务器地址:pop.gmail.com（SSL启用端口：995） SMTP服务器地址:smtp.gmail.com（SSL启用端口：587） 新浪邮箱（sina.com）: POP3服务器地址:pop3.sina.com.cn（端口：110） SMTP服务器地址:smtp.sina.com.cn（端口：25） Tom邮箱（top.com）: POP3服务器地址:pop.tom.com（端口：110） SMTP服务器地址:smtp.tom.com（端口：25） 网易邮箱（163.com）: POP3服务器地址:pop.163.com（端口：110） SMTP服务器地址:smtp.163.com（端口：25） 126邮箱: POP3服务器地址：pop.live.com（端口：995） SMTP服务器地址:smtp.126.com（端口：25） 雅虎邮箱（yahoo.com）: POP3服务器地址:pop.mail.yahoo.com SMTP服务器地址:smtp.mail.yahoo.com 雅虎中国（yahoo.com.cn）: POP3服务器地址:pop.mail.yahoo.com.cn（端口：995） SMTP服务器地址:smtp.mail.yahoo.com.cn（端口：587） 雅虎邮箱POP3的SSL不启用端口为110，POP3的SSL启用端口995；SMTP的SSL不启用端口为25，SMTP的SSL启用端口为465。 Foxmail邮箱（foxmail.com）： POP3服务器地址:POP.foxmail.com（端口：110） SMTP服务器地址:SMTP.foxmail.com（端口：25） QQ邮箱（mail.qq.com） POP3服务器地址：pop.qq.com（端口：110） SMTP服务器地址：smtp.qq.com（端口：25） SMTP服务器需要身份验证。 搜狐邮箱（sohu.com）: POP3服务器地址:pop3.sohu.com（端口：110） SMTP服务器地址:smtp.sohu.com（端口：25） HotMail邮箱（hotmail.com）： POP3服务器地址：pop.live.com（端口：995） SMTP服务器地址：smtp.live.com（端口：587 移动139邮箱: POP3服务器地址：POP.139.com（端口：110） SMTP服务器地址：SMTP.139.com(端口：25) 中华网邮箱（china.com）: POP3服务器地址:pop.china.com（端口：110） SMTP服务器地址:smtp.china.com（端口：25） 以上便是常用邮箱SMTP服务器地址大全。可能还有些邮箱木有收集到。我们在设置代收发邮件软件时候，在POP3服务器地址及SMTP服务器地址处，只需要按照以上邮箱对应填写即可。 二、如何打开POP3/SMTP/IMAP功能？ 为了保障用户邮箱的安全，QQ邮箱设置了POP3/SMTP/IMAP的开关。系统缺省设置是“关闭”，在用户需要这些功能时请“开启”。 1.首先，登录邮箱，进入设置-帐户； 然后，在“帐户”设置中，找到设置项，进行设置，如下： 最后，保存设置，即打开了相应的服务。 ","link":"https://liujinyang6.github.io/post/chang-yong-de-you-xiang-fu-wu-qi/"},{"title":"软件测试流程","content":"Posted on 2018-12-12 | In Hexo 需求分析： - 整体流程图： 需求提取 -&gt; 需求分析 -&gt; 需求评审 -&gt; 更新后的测试需求跟踪xmind - 分析流程： 需求提取： 分析依据（包括：需求矩阵、产品交互图、需求说明书） 获取需求的纬度 客户价值 可以为客户带来哪些价值？ 可以解决哪些问题？ 根据以上问题定位功能是否合理 UI功能 - 展示功能 模块关联-历史模块 新功能模块关联 考虑是否关联？耦合部分是否需要支持？ 客户使用场景-部署方式 网络特性 客户使用服务器常见外设 性能参数-性能要求 网卡最低速率 硬件支持 输出（提取最原始的测试需求） 需求分析： 分析依据（五维分析） 用户场景 功能是否和场景强关联 网络拓扑能否满足客户需求 和竞争对手比较差异 功能是否能满足客户实际应用场景 是否考虑了用户的实际操作 明确性 范围明确性（参数、类型长度范围） 清晰性限制等范畴 无法预知影响的需求提出进行确定，风险 二义性 概念模糊【大概念、第三方支持、与上个版本相同】 支持与不支持等范畴 一个需求描述能出现多种理解 完整性 需求一致性【用户需求、需求规格、需求矩阵三者是否同意】 需求完整【隐形需求】 关联性【与新老功能、与外置软件设备】 可测试性 实现测试需要的工具、方法【调试、接口命令】 定位方式【日志等形式观察】 复杂环境、容量边界、操作时过程不可见 输出 测试需求跟踪 缺陷预防bug 工具需求 整理出明确的需求点 测试地图 分析思路误区：需求和实现的区别【现有需求才有代码实现，不能把代码实现当作需求】 需求分析的意义 明确产品给客户带来的价值 明确产品支持和不支持的功能 明确产品各个功能的约束性 知道开发实现功能 知道测试分析和产出测试点 测试设计： - 测试分析： 我们需要做什么？ 把明确的需求点转换成测试项 缺陷预防 怎么做？ 整体模块分析 逻辑分析【这一点主要是从产品实现的原理上去分析可能的影响】 怎么做？ 开发的设计文档 补充和挖掘测试点 全部服务的异常监控、服务重启 各类存储对空间的占用、占满、是否需要做存储的接口测试 所有类型的管理员、操作权限测试、支持的多少管理员并发操作 对流程图的挖掘 – 流程图全部流程测试、流程图重要的节点异常测试 对状态的挖掘 – 所有状态的相互转化需要覆盖全、状态转化是否合理、每一个状态下哪些操作可做哪些不可做，多个状态是否可以共存 对关联项的挖掘 – 流程进展到哪一步关机重启/服务重启、和备份配置的关联，和操作日志的关联等等 任务的并发操作测试、是否可配置、是否会出现性能不足，是否符合用户场景 异常处理机制测试，异常处理机制是否完善 指标测试，开发的指标设计是否合理 修正不合理的需求 如何分析 逻辑原理： 该模块是否涉及到一些全新的概念(比如我们的 bbc 全量包)，需要明确? 该模块包括哪些服务? 该模块涉及到哪些存储技术(如 mysql、dap、redis)?具体怎么存储的?占用大小如何? 该模块的操作流程有哪些?是否有子流程图? 该模块是否有多个状态的转化?是否有明确的状态转化图? 该模块对多个管理员是否区分，管理员权限如何设计? 该模块是否有一些特殊的操作限制?操作限制是否有明确的表格? 该模块的任务是否有并发需求?并发的设计? 该模块的所有指标如何? 该模块是否有异常处理机制?在设备各种异常时，该模块的设计是否满足能稳健运行? 场景分析 从用户的使用习惯和使用方法去分析影响 检查当前案例是否覆盖到用户场景 关联测试分析： 考虑你的模块所在整个系统的地位，分析上下游的影响 对老功能的影响 经验补充分析 版本分析 模块分析 输出 测试项 补充测试地图 - 测试设计： 需要做什么？ 把测试项细化成测试点 缺陷预防 需要做什么？ 基本设计方法 等价类划分法【将输入域和输出域划分为不同的等价类，等价类之内的操作结果相同】，使用范围：显示输入框输入 边界值法【需要结合等价类划分法方法，在划分出来的等价类选取有代表性的值】 正反对比【一般会放到同一个用例里覆盖】 字符多样性【考虑不同字符的输入】 测试类型 产品专项测试 正交组合设计【正交矩阵，覆盖各个参数间的组合情况】 业务逻辑设计【根据业务设计测试点】 输出： 基本测试点 - 用例设计： 需要做什么？ 把测试点用文字完整表述出来 怎么做？ 功能用例框架： 模块框架模板 需求类 UI测试【如果UI用例可以被功能用例覆盖，这里可以不写】 公共测试类： 链接 选中会有高亮显示 点击跳转到对应页面 当前页面对应的名称下有区别显示 翻页 按钮 输入框【这个功能用例一般可以覆盖】 下拉框 排序 条目选择【这个很重要，第一次集成测试一定要保证每个选项都是有效的】 搜索 所有字符类型验证 为空验证 模糊搜索 精确搜索 搜索不存在的关键词 刷新 验证自动刷新 验证手动刷新 验证持续刷新 拖动 移动 点击下移，往下移动一行 点击上移，往上移动一行 最上面的行，上移不能点击，图标灰色 最下面的行，下移不能点击，图标灰色 功能测试 测试点： 功能基本流程逻辑覆盖 业务流程多样性覆盖 用户操作习惯的多样性 模块配置的多样性 数据流的多样性覆盖 测试目录 平级分类相对独立 上下级分类有关联 下级从上级细化而来 关联类： 模块与模块之间的 模块与功能之间 模块与硬件之间 场景类 建模思路 部署方式【比如用户一般使用2主机还是3主机部署集群】 数据流 业务流【用户是怎么使用申请工单，是怎么样的完整流程】 操作顺序【创建云主机的顺序之类的】 配置方法【用户一般怎么配置使用静态路由】 使用时间【用户会不会连续长时间开启云主机】 用户角色【一般那些角色做什么操作】 用户操作的设计方向 最常用的功能 最容易出现网上问题的功能 典型客户使用的功能 版本的性能验证 专项类 兼容性 可靠性【测试产品在异常情况下能否正常工作或者是恢复正常工作，可靠性重点测试对模块自身处理的覆盖】. 补充：容错性测试【测试系统在非正常操作、非正常的外部环境下是否能够处理错误和正常运行】 eg： 针对数据库的测试：【磁盘空间不足、数据库文件损坏、无读写数据权限、写数据时断电、写数据时强制关闭mysql、读写速度】 针对网络设备：【网络中有攻击数据、丢包时延大、IP冲突、网络线路断开、同时掉电】 针对程序：【 客户端进程被手动停止、设备后台资源cpu、内存占满】 安全性【主要是验证程序有哪些缺陷可能会造成安全方面的问题】 eg： 密码加密方式【什么时候用明文，什么时候用密码显示】 隐私数据隐藏【用户的隐私显示】 设备的完整目录【完整的目录会增加后台被攻击的危险】 文件上传功能【检查上传的文件类型；限制上传文件的权限】 防暴力破解【对于连线认证之类的操作要冻结、禁用其连续错误尝试操作】 脚本测试 使用注意细节 文件夹以01-xx，02-xx区分开 每个文件夹下不能超过10个用例 每个测试用例一个测试点 在02-功能测试的描述中，备注说明功能测试框架的思路 - 用例整体规范： 用例标题【好的标题需要准确的表达你的测试目的、要测试的测试点】 eg： 测试。。。 验证。。。 。。。的测试 与。。。的关联测试 。。。的异常测试 。。。的兼容性测试 用例属性 测试环境【默认的前置条件可以不用写；写的前置条件要准确，不要写的模糊】 测试方法 优先级 BVT【最最最基本的功能】-BVT(10%)：模块最基本的功能验证(含常用部署、基本关联)，推荐1级用例的20%左右 level1【基本操作、基本场景】-Leve1(30%)：基本需求点，基本逻辑，基本可靠性，基本关联，基本用户场景 level2【比较少见的正常操作】-Leve2(40%)：常见功能/逻辑细化点/专项细化点，常见关联/容错/边界值/用户场景 level3【异常操作；后续不需要再执行】-Leve3(20%)：错误提示、极少测试的用例、非常见部署方式/用户场景/容错/边界值等 用例格式 前置条件 测试步骤【单个用例全部步骤不能超过8步】 后置条件【不是必填的】 预期结果 备注【不是必填的】 语言规范 语言简练 不能出现模糊的形容词【比如说大概、可能、很多、差不多】 可维护性 灵活运用模块备注 设计原则 目的明确【一个用例对应一个测试点；测试步骤和测试目的一致】 用例效率 保证设计出来的用例10分钟内可以执行完成； 用例需要的环境可以整理出来，然后写到模块备注中，让执行者先准备好环境一次性执行全部用例； 执行的时候按照测试集方式来执行； 有工具可以实现的用例不要采用脚本方式实现 测试步骤： 用户角度 设计的用例要符合用户的操作顺序和操作习惯 符合用户的使用环境 符合用户的配置 可执行 不要出现那种用例设计没有错，但是执行起来很复杂或者是依赖环境很夸张的用例 正反对比 这一点很重要，很多时候我们会把有正反操作的用例分开写，其实是可以合在一个用例里面写 强弱关联 对于强关联的步骤一定要写清楚 对于弱关联的可以备注或者是不写 测试用例不能出现操作步骤 直接写需要做的操作就可以了 预期结果： 用户角度： 反思用户期望操作完会有什么结果 反思客户最关注的测试点 可检查 预期结果要可以观察到，不要写的很模糊 把重点检查的检查点覆盖到 用例编写口诀 强弱正反之业务 重点突出之效率 目的明确之语言 框架覆盖之检查 逻辑场景之经验 ","link":"https://liujinyang6.github.io/post/ruan-jian-ce-shi-liu-cheng/"},{"title":"Hello Gridea","content":"👏 欢迎使用 Gridea ！ ✍️ Gridea 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ... Github Gridea 主页 示例网站 特性👇 📝 你可以使用最酷的 Markdown 语法，进行快速创作 🌉 你可以给文章配上精美的封面图和在文章任意位置插入图片 🏷️ 你可以对文章进行标签分组 📋 你可以自定义菜单，甚至可以创建外部链接菜单 💻 你可以在 Windows，MacOS 或 Linux 设备上使用此客户端 🌎 你可以使用 𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌 或 Coding Pages 向世界展示，未来将支持更多平台 💬 你可以进行简单的配置，接入 Gitalk 或 DisqusJS 评论系统 🇬🇧 你可以使用中文简体或英语 🌁 你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力 🖥 你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步 🌱 当然 Gridea 还很年轻，有很多不足，但请相信，它会不停向前 🏃 未来，它一定会成为你离不开的伙伴 尽情发挥你的才华吧！ 😘 Enjoy~ ","link":"https://liujinyang6.github.io/post/hello-gridea/"},{"title":"Hadoop+Zookeeper+Spark+Hbase大数据平台搭建","content":"Posted on 2018-06-10 | In Hexo 前言 随着这学期对于hbase和spark的学习，加上上学期学习的hadoop知识，这次专周在这一年学习的基础上，使用虚拟机或者实机&gt;搭建一个伪分布式大数据平台，涉及hadoop平台、hbase平台还有spark平台，使用一台虚拟机充当主节点master，两台虚拟机&gt;充当子节点slave、slave1。 前期准备 hadoop-2.7.6.tar.gz hbase-1.2.6-bin.tar.gz jdk-8u161-linux-x64.tar.gz zookeeper-3.4.10.tar.gz sqoop-1.99.7.tar.gz spark-2.2.1-bin-hadoop2.7.tgz kafka_2.11-1.1.0.tgz 修改hostname 在root用户下的主界面运行一下命令： $ vim /etc/hostname 将localhost修改为姓名缩写和学号后四位然后:wq保存退出。 在每个节点/etc/hosts中加入本机ip和其他节点ip 在root用户下的主界面运行一下命令： $ vim /etc/hosts 添加以下内容： 127.0.0.1 localhost 10.19.2.197 ljy0326 10.19.2.209 pxc0305 10.19.1.242 huwei0303 必须保证hosts内每个ip对应的主机名与hostname一致 配置免密登录 代码如下： $ sudo apt-get install ssh $ ssh-keygen -t rsa $ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys $ sudo gedit authorized_keys $ ssh huwei0303 添加完成，效果如图： 下载资源 下载JDK 请登录如下网站，下载你想要的版本http://www.oracle.com/technetwork/cn/java/javase/downloads/jdk8-downloads-2133151-zhs.html 下载Hadoop等其他安装包 https://mirrors.tuna.tsinghua.edu.cn/apache/ 需要下载 Hadoop、HBase、Spark、Scala、Sqoop、kafka、Zookeeper 解压文件 解压命令： tar -zxvf ****.gz -C /opt/文件夹名 将jdk1.8.0_144文件夹更名为java 将hadoop-2.6.7 文件夹更名为hadoop 其余文件夹同上。 在每个节点配置环境变量 执行以下命令： $ vim /etc/profile 在文件最后输入以下内容： export JAVA_HOME=/opt/java export HADOOP_HOME=/opt/hadoop export ZOOKEEPER_HOME=/opt/zookeeper export HBASE_HOME=/opt/hbase export SPARK_HOME=/opt/spark export SCALA_HOME=/opt/scala export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf:$HBASE_HOME/bin:$SPARK_HOME/bin:$SCALA_HOME/bin:$SQOOP_HOME/bin 配置如图： 保存退出后需使环境变量生效，执行以下命令： $ source /etc/profile 然后生效后运行java -version查看jdk配置是否成功 在每个节点创建文件夹并改权限 该文件夹为Hadoop相关文件夹 创建命令： $ mkdir -p /opt/hadoop 将主节点设置为NTP服务器 一个Hadoop集群就是一个小型局域网，我们需要设定一台NTP服务器作为整个网络的标准时间参考，使用网络（集群）内的所有机器保持时间一致！以下是详细的操作步骤： 安装ntp软件 执行命令： $ apt-get install ntp 修改配置文件 打开文件需要修改的配置文件,执行以下命令： $ vim /etc/ntp.conf # Specify one or more NTP servers server 127.127.1.0 因为是内网，所以用本地时间做为服务器时间，注意这里不是127.0.0.1 在配置文件里找到以下4条并注释掉: #server 0.ubuntu.pool.ntp.org #server 1.ubuntu.pool.ntp.org #server 2.ubuntu.pool.ntp.org #server 3.ubuntu.pool.ntp.org 增加了NTP服务器自身到时间服务器的同步 fudge 127.127.1.0 stratum 8 增加了一些需要同步的客户端的ip restrict -4 default kod notrap nomodify nopeer noquery limited restrict -6 default kod notrap nomodify nopeer noquery limited restrict 10.19.2.209 restrict 10.19.1.242 配置完成如图： 配置Hadoop 配置 hadoop-env.sh # The java implementation to use. 修改为自己的JAVA_HOME路径 export JAVA_HOME=/opt/java/jdk-8u171-linux-x64 配置hdfs-site.xml 配置如图： 配置core-site.xml 配置如图： 配置mapred-site.xml 配置如图： 配置slaves 添加节点的主机名： ljy0326 pxc0305 huwei0303 添加完毕后保存退出。 配置 yarn-site.xml 如图： 配置JournalNode JournalNode的配置是在hdfs-site.xml文件中， 打开文件： $ vim hdfs-site.xml 在原有的配置下面添加一下内容，需保证所有的内容均在 &lt;!--指定hdfs的nameservice为ljy0326，需要和core-site.xml中的保持一致--&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ljy0326&lt;/value&gt; &lt;/property&gt; &lt;!-- ns下面有两个NameNode，分别是nn1，nn2--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ljy0326&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;!--配置 nn1的RPC通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ljy0326.nn1&lt;/name&gt; &lt;value&gt;ljy0326:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置nn1的http通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ljy0326.nn1&lt;/name&gt; &lt;value&gt;ljy0326:50070&lt;/value&gt; &lt;/property&gt; &lt;!--配置 nn2的RPC通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ljy0326.nn2&lt;/name&gt; &lt;value&gt;pxc0305:9000&lt;/value&gt; &lt;/property&gt; &lt;!--配置nn2的http通信地址--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ljy0326.nn2&lt;/name&gt; &lt;value&gt;pxc0305:50070&lt;/value&gt; &lt;/property&gt; &lt;!--指定NameNode的元数据在JournalNode上的存放位置--&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://ljy0326:8485;pxc0305:8485;huwei0303:8485/ljy0326&lt;/value&gt; &lt;/property&gt; &lt;!--指定JournalNode在本地磁盘存放数据的位置--&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/journal&lt;/value&gt; &lt;/property&gt; &lt;!--开启NameNode故障时自动切换--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!--配置失败自动切换实现方式--&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ljy0326&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyPrivider&lt;/value&gt; &lt;/property&gt; &lt;!--配置隔离机制，如果ssh是默认22端口，value直接写sshfence即可--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence(ljy0326:22)&lt;/value&gt; &lt;/property&gt; &lt;!--使用隔离机制时需要ssh免登陆--&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; 将配置好的文件发送到其他节点: 运行shell命令: $ scp –r /opt/java/jdk root@huwei0303:/opt/java $ scp –r /opt/java/jdk root@pxc0305:/opt $ scp –r /opt/hadoop/hadoop-2.6.7 root@huwei0303:/opt/hadoop $ scp –r /opt/hadoop/hadoop-2.6.7 root@pxc0305:/opt/hadoop 格式化namenode 在master节点运行shell命令: $ hadoop namenode –format 提示0，则格式化正常 启动hadoop集群 运行命令： $ /sbin/start-all.sh 输入命令jps，hadoop启动成功如图： 配置ZooKeeper 创建相关文件 $ sudo mkdir -p /usr/local/zkData //该文件夹为Zookeeper数据文件夹 $ mkdir -p /opt/zookeeper/logs //该文件夹存放Zookeeper 日志文件 在ljy0326节点运行shell命令: $ echo 1 &gt;&gt; /usr/local/zkData/myid 在pxc0305 节点运行shell命令 $ echo 2 &gt;&gt; /usr/local/zkData/myid 在huwei0303 节点运行shell命令 $ echo 3 &gt;&gt; /usr/local/zkData/myid 配置/opt/zookeeper/conf/zoo.cfg # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. # 将此处改为原先创建好的目录 dataDir=/usr/local/zkData # the port at which the clients will connect clientPort=2181 server.1=0.0.0.0:2888:3888 server.2=pxc0305:2888:3888 server.3=huwei0303:2888:3888 配置完成如图： 注意此处（3个虚拟机要分别配置） 在pxc0305节点，将此处配置为 server.1=ljy0326:2888:3888 server.2=0.0.0.0:2888:3888 server.3=huwei0303:2888:3888 在huwei0303节点，将此处配置为 server.1=ljy0326:2888:3888 server.2=pxc0305:2888:3888 server.3=0.0.0.0:2888:3888 配置/opt/zookeeper/bin/zkEnv.sh 找到 if [ &quot;x${ZOO_LOG_DIR}&quot; = &quot;x&quot; ] then ZOO_LOG_DIR=&quot;.&quot; fi 将.改为/opt/zookeeper/logs 将配置文件发送到其他节点 运行shell命令： $ scp –r /opt/zookeeper/ root@pxc0305:/opt $ scp –r /opt/zookeeper/ root@huwei0303:/opt 启动Zookeeper集群 在每个节点运行shell命令: $ zkServer.sh start 配置HBase 配置hbase-env.sh export JAVA_HOME=/opt/java/jdk //更改Java环境变量 配置hbase-site.xml &lt;configuration&gt; &lt;property&gt; //集群中所有RegionServer共享目录 &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://ljy0326:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //集群的模式 &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; // zookeeper集群的URL配置 &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;ljy0326,pxc0305,huwei0303&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //指定ljy0326 &lt;name&gt;hbase.master&lt;/name&gt; &lt;value&gt;ljy0326&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //客户端与zookeeper的连接端口 &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //客户端与zookeeper的通讯超时时间 &lt;name&gt;zookeeper.session.timeout.ms&lt;/name&gt; &lt;value&gt;1800000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; // RegionServer处理IO请求的线程数 &lt;name&gt;hbase.regionserver.handler.count&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;/property&gt; &lt;property&gt; //RegionServer发生Split的阔值 &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt; &lt;value&gt;2147483648&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置regionservers pxc0305 huwei0303 将配置文件发送到其他节点 $ scp –r /opt/hbase/ root@pxc0305:/opt $ scp –r /opt/hbase/ root@huwei0303:/opt 在master节点启动HBase $ start-hbase.sh 输入命令jps，Hbase启动成功如图： 搭建spark 在每个节点创建Spark相关目录: $ sudo mkdir –p /usr/local/spark //该目录用于存放worker信息和日志 配置spark-env.sh文件 配置如图： #在配置slave节点时，将SPARK_LOCAL_IP改为对应的IP地址或者Hostname 配置spark-defaults.conf 配置如图： 配置slaves #在文件中加入配置信息 pxc0305 huwei0303 将配置文件发送到其他节点 运行shell命令： $ scp –r /opt/spark/ root@pxc0305:/opt $ scp –r /opt/spark/ root@huwei0303:/opt $ scp –r /opt/scala/ root@pxc0305:/opt $ scp –r /opt/scala/ root@huwei0303:/opt 启动Spark集群 #在Hadoop集群启动的情况下运行以下命令: $ /opt/spark/spark-2.2.1/sbin/start-all.sh 搭建kafka 创建kafka相关目录 $ mkdir /opt/kafka/logs //存放kafka消息的目录，也可以使用默认的目录 修改配置文件 $ vim /opt/kafka/ kafka_2.11-1.1.0 /config/server.properties 需要修改的部分: broker.id=1 //当前机器在kafka机器里唯一标识，与zookeeper的myid相匹配 log.dirs=/opt/kafka/logs //存储消息的目录位置 将配置文件发送到其他节点 运行shell命令: scp –r /opt/spark/ root@pxc0305:/opt scp –r /opt/spark/ root@huwei0303:/opt 切换到pxc0305和huwei0303上修改配置文件: [root@pxc0305]# vim server.properties broker.id=2 [root@ huwei0303]# vim server.properties broker.id=3 启动kafka集群 保证先启动zookeeper集群 然后在每个节点的、kafka/sbin目录下运行 $ cd /opt/kafka/ kafka_2.11-1.1.0/sbin $ ./kafka-server-start.sh -daemon ../config/server.properties 若成功启动，输入jps可以看到 kafka 搭建sqoop1.99.7 配置第三方jar引用路径 $ vim /etc/profile $ export SQOOP_SERVER_EXTRA_LIB=$SQOOP_HOME/extra 最后把mysql的驱动jar文件复制到这个目录下。 配置sqoop.properties文件 org.apache.sqoop.submission.engine.mapreduce.configuration.directory=/opt/hadoop/etc/hadoop org.apache.sqoop.security.authentication.type=SIMPLE org.apache.sqoop.security.authentication.handler=org.apache.sqoop.security.authentication.SimpleAuthenticationHandler org.apache.sqoop.security.authentication.anonymous=true 验证配置是否有效 使用bin中的sqoop2-tool工具进行验证： $ bin/sqoop2-tool verify 这个工具也可用于软件升级。若没有什么问题，往下走。 启动sqoop $ bin/sqoop2-server start 安装mysql 在ljy0326上运行命令 $ apt-get install mysql-server-5.6 会提示设置root密码，设置完成则运行查看是否成功 检测搭建是否完成 搭建成功后每个节点jps运行截图： 结果如上图，大功告成！ ","link":"https://liujinyang6.github.io/post/hadoopzookeepersparkhbase-da-shu-ju-ping-tai-da-jian/"},{"title":"Github Pages+Hexo+腾讯云域名绑定","content":"Github Pages+Hexo+腾讯云域名绑定 Posted on 2018-05-14 | In Hexo Github Pages Github Pages可以免费托管，所以把博客托管到github上。 首先，创建一个github仓库，仓库的命名格式为：yourusername.github.io，然后根据提示进行下一步。 hexo搭建博客 本博客中使用了next的主题，所以会详细介绍下按照next主题搭建的步骤。 准备工作 1.首先要安装下node.js（官网下载）,如果已经安装可以跳过。 2.安装git（官网下载）。 3.安装Hexo： $ npm install -g hexo 安装成功后，使用version命令查看是否安装成功 $ hexo version 4.本地静态hexo博客 新建一个文件夹，作为你博客文件的根目录 命令行进入该文件夹下,输入以下命令，生成模板： $ hexo init 模板生成后，输入以下命令： $ npm install 最后可以运行hexo s命令查看是否搭建成功 下载主题 在 themes 文件夹内，新增一个next文件夹，并修改_config.yml 内的 theme 设定theme: next，即可切换到next主题。然后把next主题的内容clone到刚刚新建的next文件夹下: git clone https://github.com/liuJinYang6/hexo-theme-next.git themes/next 配置博客 1.用户信息配置 根据个人需求进行相关配置。 注意：在themes/next目录中的_config.yml中配置一下信息，而非博客根目录下的_config.yml中配置。ps:不过我的有些没起作用的就放到了根目录下的_config.yml中。 2.创建About页面 在根目录下的source文件夹里创建一个about文件夹，然后在about文件夹里新建index.md文件,在文件中添加如下代码，并保存： --- title: 关于我 date: 2016-10-10 15:40:19 --- 具体介绍信息根据个人进行添加。 部署Hexo博客 建站 $ hexo init yourname $ cd yourname $ npm install 配置_config.yml的部署: deploy: type: git repository: git@github.com:liuJinYang6/liuJinYang6.github.io.git branch: master 清理缓存 $ hexo clean 生成静态网页 $ hexo g 本地查看效果，执行完后可以通过http://localhost:4000查看本地效果 $ hexo s 部署到git $ hexo d 绑定腾讯云域名 之前在腾讯云买了域名，域名购买成功之后要等待实名认证。 添加CNAME文件 在根目录下的source文件夹下新建CNAME文件，没有后缀。打开CNAME文件，在里面添加你的域名信息，保存之后，重新部署到github pages上。 给github项目添加 在项目的Settings中，添加Custom domain到自己的域名。 给域名添加解析记录 1.ping你自己的yourname.github.io获取到ip地址； 2.打开域名的解析列表，添加两条解析记录； 更换之后，可能需要等一段时间才能生效，差不多就大功告成啦。 ","link":"https://liujinyang6.github.io/post/github-pageshexoteng-xun-yun-yu-ming-bang-ding/"}]}